
@InProceedings{Zhan_2018_CVPR,
author = {Zhan, Huangying and Garg, Ravi and Saroj Weerasekera, Chamara and Li, Kejie and Agarwal, Harsh and Reid, Ian},
title = {Unsupervised Learning of Monocular Depth Estimation and Visual Odometry With Deep Feature Reconstruction},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@online{noauthor_v-net:_nodate,
	title = {V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation - {IEEE} Conference Publication},
	url = {https://ieeexplore.ieee.org/abstract/document/7785132/},
	urldate = {2018-09-14},
	file = {V-Net\: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation - IEEE Conference Publication:/Users/Marc/Zotero/storage/PGVC2XZ5/7785132.html:text/html}
}

@inproceedings{ronneberger_u-net:_2015,
	  author       = "O. Ronneberger and P.Fischer and T. Brox",
  title        = "U-Net: Convolutional Networks for Biomedical Image Segmentation",
  booktitle    = "Medical Image Computing and Computer-Assisted Intervention (MICCAI)",
  series       = "LNCS",
  volume       = "9351",
  pages        = "234--241",
  year         = "2015",
  publisher    = "Springer",
  note         = "(available on arXiv:1505.04597 [cs.CV])",
  url          = "http://lmb.informatik.uni-freiburg.de/Publications/2015/RFB15a"
}

@incollection{krizhevsky_imagenet_2012,
title = {ImageNet Classification with Deep Convolutional Neural Networks},
author = {Alex Krizhevsky and Sutskever, Ilya and Hinton, Geoffrey E},
booktitle = {Advances in Neural Information Processing Systems 25},
editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
pages = {1097--1105},
year = {2012},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}
}

@article{long_fully_2015,
author={E. Shelhamer and J. Long and T. Darrell}, 
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
title={Fully Convolutional Networks for Semantic Segmentation}, 
year={2017}, 
volume={39}, 
number={4}, 
pages={640-651}, 
keywords={feedforward neural nets;image classification;image representation;image resolution;image segmentation;learning (artificial intelligence);transforms;fully convolutional networks;semantic segmentation;visual models;correspondingly-sized output;spatially dense prediction tasks;contemporary classification networks;learned representations;coarse layer;fine layer;PASCAL VOC;NYUDv2;SIFT Flow;PASCAL-Context;Semantics;Image segmentation;Training;Convolution;Computer architecture;Proposals;Fuses;Semantic Segmentation;Convolutional Networks;Deep Learning;Transfer Learning}, 
doi={10.1109/TPAMI.2016.2572683}, 
ISSN={0162-8828}, 
month={April},}

@article{vilarino_discrete-time_1998,
title = "Discrete-time CNN for image segmentation by active contours",
journal = "Pattern Recognition Letters",
volume = "19",
number = "8",
pages = "721 - 734",
year = "1998",
issn = "0167-8655",
doi = "https://doi.org/10.1016/S0167-8655(98)00050-6",
url = "http://www.sciencedirect.com/science/article/pii/S0167865598000506",
author = "D.L. Vilariño and V.M. Brea and D. Cabello and J.M. Pardo",
keywords = "Deformatile models, Active contours, Model-based segmentation, Discrete-time cellular neural networks, Cellular neural networks"
}

@article{chen_deeplab:_2018,
author={L. Chen and G. Papandreou and I. Kokkinos and K. Murphy and A. L. Yuille}, 
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
title={DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs}, 
year={2018}, 
volume={40}, 
number={4}, 
pages={834-848}, 
keywords={convolution;feature extraction;feedforward neural nets;image segmentation;learning (artificial intelligence);random processes;highlight convolution;atrous convolution;Deep Convolutional Neural Networks;atrous spatial pyramid pooling;image context;fully connected Conditional Random Field;PASCAL VOC-2012 semantic image segmentation task;deep convolutional nets;Deep Learning;DeepLab;semantic image segmentation;probabilistic graphical models;Convolution;Image segmentation;Semantics;Image resolution;Computational modeling;Neural networks;Context;Convolutional neural networks;semantic segmentation;atrous convolution;conditional random fields}, 
doi={10.1109/TPAMI.2017.2699184}, 
ISSN={0162-8828}, 
month={April},}

@article{zhang_deep_2015,
title = "Deep convolutional neural networks for multi-modality isointense infant brain image segmentation",
journal = "NeuroImage",
volume = "108",
pages = "214 - 224",
year = "2015",
issn = "1053-8119",
doi = "https://doi.org/10.1016/j.neuroimage.2014.12.061",
url = "http://www.sciencedirect.com/science/article/pii/S1053811914010660",
author = "Wenlu Zhang and Rongjian Li and Houtao Deng and Li Wang and Weili Lin and Shuiwang Ji and Dinggang Shen",
keywords = "Image segmentation, Multi-modality data, Infant brain image, Convolutional neural networks, Deep learning"
}

@online{noauthor_deep_nodate,
	title = {Deep Convolutional Neural Networks for Computer-Aided Detection: {CNN} Architectures, Dataset Characteristics and Transfer Learning},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4

\ref
 

Replace with
 
Track changes is off
Everyone
You
marcmoreno.92
Guests
Current file
Overview
4
890616/},
	urldate = {2018-09-14},
	file = {Deep Convolutional Neural Networks for Computer-Aided Detection\: CNN Architectures, Dataset Characteristics and Transfer Learning:/Users/Marc/Zotero/storage/QGX47NME/PMC4890616.html:text/html}
}

@article{pham2000current,
  title={Current methods in medical image segmentation},
  author={Pham, Dzung L and Xu, Chenyang and Prince, Jerry L},
  journal={Annual review of biomedical engineering},
  volume={2},
  number={1},
  pages={315--337},
  year={2000},
  publisher={Annual Reviews 4139 El Camino Way, PO Box 10139, Palo Alto, CA 94303-0139, USA}
}

@inproceedings{liu_semantic_2015,
author = {Liu, Ziwei and Li, Xiaoxiao and Luo, Ping and Loy, Chen-Change and Tang, Xiaoou},
 title = {Semantic Image Segmentation via Deep Parsing Network},
 booktitle = {Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV)},
 series = {ICCV '15},
 year = {2015},
 isbn = {978-1-4673-8391-2},
 pages = {1377--1385},
 numpages = {9},
 url = {http://dx.doi.org/10.1109/ICCV.2015.162},
 doi = {10.1109/ICCV.2015.162},
 acmid = {2920082},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
}

@incollection{dai_r-fcn:_2016,
title = {R-FCN: Object Detection via Region-based Fully Convolutional Networks},
author = {Dai, Jifeng and Li, Yi and He, Kaiming and Sun, Jian},
booktitle = {Advances in Neural Information Processing Systems 29},
editor = {D. D. Lee and M. Sugiyama and U. V. Luxburg and I. Guyon and R. Garnett},
pages = {379--387},
year = {2016},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/6465-r-fcn-object-detection-via-region-based-fully-convolutional-networks.pdf}
}

@online{noauthor_deep_nodate-1,
	title = {Deep learning {\textbar} Nature},
	url = {https://www.nature.com/articles/nature14539},
	urldate = {2018-09-14},
	file = {Deep learning | Nature:/Users/Marc/Zotero/storage/GXA5MZN2/nature14539.html:text/html}
}

@inproceedings{prasoon_deep_2013,
author="Prasoon, Adhish
and Petersen, Kersten
and Igel, Christian
and Lauze, Fran{\c{c}}ois
and Dam, Erik
and Nielsen, Mads",
editor="Mori, Kensaku
and Sakuma, Ichiro
and Sato, Yoshinobu
and Barillot, Christian
and Navab, Nassir",
title="Deep Feature Learning for Knee Cartilage Segmentation Using a Triplanar Convolutional Neural Network",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2013",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="246--253",
abstract="Segmentation of anatomical structures in medical images is often based on a voxel/pixel classification approach. Deep learning systems, such as convolutional neural networks (CNNs), can infer a hierarchical representation of images that fosters categorization. We propose a novel system for voxel classification integrating three 2D CNNs, which have a one-to-one association with the xy, yz and zx planes of 3D image, respectively. We applied our method to the segmentation of tibial cartilage in low field knee MRI scans and tested it on 114 unseen scans. Although our method uses only 2D features at a single scale, it performs better than a state-of-the-art method using 3D multi-scale features. In the latter approach, the features and the classifier have been carefully adapted to the problem at hand. That we were able to get better results by a deep learning architecture that autonomously learns the features from the images is the main insight of this study.",
isbn="978-3-642-40763-5"
}


@article{liu2015crf,
  title={CRF learning with CNN features for image segmentation},
  author={Liu, Fayao and Lin, Guosheng and Shen, Chunhua},
  journal={Pattern Recognition},
  volume={48},
  number={10},
  pages={2983--2992},
  year={2015},
  publisher={Elsevier}
}

@ARTICLE{Moeskops_automatic_segmentation, 
author={P. Moeskops and M. A. Viergever and A. M. Mendrik and L. S. de Vries and M. J. N. L. Benders and I. Išgum}, 
journal={IEEE Transactions on Medical Imaging}, 
title={Automatic Segmentation of MR Brain Images With a Convolutional Neural Network}, 
year={2016}, 
volume={35}, 
number={5}, 
pages={1252-1261}, 
keywords={biological tissues;biomedical MRI;brain;image segmentation;medical image processing;neural nets;neurophysiology;paediatrics;automatic MR brain image segmentation;convolutional neural network;quantitative analysis;spatial consistency;multiple patch sizes;multiple convolution kernel sizes;multiscale information;training data;coronal T2-weighted images;preterm infants;postmenstrual age;axial T2-weighted images;ageing adults;average Dice coefficients;segmented tissue classes;acquisition protocol;Image segmentation;Brain;Pediatrics;Kernel;Convolution;Biomedical imaging;Aging;Adult brain;automatic image segmentation;convolutional neural networks;deep learning;MRI;preterm neonatal brain;Adult;Aged;Brain;Humans;Image Processing, Computer-Assisted;Infant, Newborn;Infant, Premature;Machine Learning;Magnetic Resonance Imaging;Neural Networks (Computer);Young Adult}, 
doi={10.1109/TMI.2016.2548501}, 
ISSN={0278-0062}, 
month={May},}

@InProceedings{Dong_2018_CVPR,
author = {Dong, Xuanyi and Yu, Shoou-I and Weng, Xinshuo and Wei, Shih-En and Yang, Yi and Sheikh, Yaser},
title = {Supervision-by-Registration: An Unsupervised Approach to Improve the Precision of Facial Landmark Detectors},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Hu_2018_CVPR,
author = {Hu, Lanqing and Kan, Meina and Shan, Shiguang and Chen, Xilin},
title = {Duplex Generative Adversarial Network for Unsupervised Domain Adaptation},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}
@InProceedings{Yin_2018_CVPR,
author = {Yin, Zhichao and Shi, Jianping},
title = {GeoNet: Unsupervised Learning of Dense Depth, Optical Flow and Camera Pose},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Wang_2018_CVPR,
author = {Wang, Jingya and Zhu, Xiatian and Gong, Shaogang and Li, Wei},
title = {Transferable Joint Attribute-Identity Deep Learning for Unsupervised Person Re-Identification},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Qu_2018_CVPR,
author = {Qu, Ying and Qi, Hairong and Kwan, Chiman},
title = {Unsupervised Sparse Dirichlet-Net for Hyperspectral Image Super-Resolution},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Zhang_2018_CVPR,
author = {Zhang, Yuting and Guo, Yijie and Jin, Yixin and Luo, Yijun and He, Zhiyuan and Lee, Honglak},
title = {Unsupervised Discovery of Object Landmarks as Structural Representations},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}
@InProceedings{Kundu_2018_CVPR,
author = {Nath Kundu, Jogendra and Krishna Uppala, Phani and Pahuja, Anuj and Venkatesh Babu, R.},
title = {AdaDepth: Unsupervised Content Congruent Adaptation for Depth Estimation},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Hoshen_2018_CVPR,
author = {Hoshen, Yedid and Wolf, Lior},
title = {Unsupervised Correlation Analysis},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}
@InProceedings{Dizaji_2018_CVPR,
author = {Ghasedi Dizaji, Kamran and Zheng, Feng and Sadoughi, Najmeh and Yang, Yanhua and Deng, Cheng and Huang, Heng},
title = {Unsupervised Deep Generative Adversarial Hashing Network},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}


@InProceedings{Saito_2018_CVPR,
author = {Saito, Kuniaki and Watanabe, Kohei and Ushiku, Yoshitaka and Harada, Tatsuya},
title = {Maximum Classifier Discrepancy for Unsupervised Domain Adaptation},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}
@InProceedings{Wu_2018_CVPR,
author = {Wu, Zhirong and Xiong, Yuanjun and Yu, Stella X. and Lin, Dahua},
title = {Unsupervised Feature Learning via Non-Parametric Instance Discrimination},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Xu_2018_CVPR,
author = {Xu, Ruijia and Chen, Ziliang and Zuo, Wangmeng and Yan, Junjie and Lin, Liang},
title = {Deep Cocktail Network: Multi-Source Unsupervised Domain Adaptation With Category Shift},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Wang_occlusion_2018_CVPR,
author = {Wang, Yang and Yang, Yi and Yang, Zhenheng and Zhao, Liang and Wang, Peng and Xu, Wei},
title = {Occlusion Aware Unsupervised Learning of Optical Flow},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Zhang_collaborative_2018_CVPR,
author = {Zhang, Weichen and Ouyang, Wanli and Li, Wen and Xu, Dong},
title = {Collaborative and Adversarial Network for Unsupervised Domain Adaptation},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}


@InProceedings{Dalca_2018_CVPR,
author = {Dalca, Adrian V. and Guttag, John and Sabuncu, Mert R.},
title = {Anatomical Priors in Convolutional Networks for Unsupervised Biomedical Segmentation},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Kanezaki_2018_CVPR,
author = {Kanezaki, Asako and Matsushita, Yasuyuki and Nishida, Yoshifumi},
title = {RotationNet: Joint Object Categorization and Pose Estimation Using Multiviews From Unsupervised Viewpoints},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}
@InProceedings{Volpi_2018_CVPR,
author = {Volpi, Riccardo and Morerio, Pietro and Savarese, Silvio and Murino, Vittorio},
title = {Adversarial Feature Augmentation for Unsupervised Domain Adaptation},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}
@InProceedings{Mahjourian_2018_CVPR,
author = {Mahjourian, Reza and Wicke, Martin and Angelova, Anelia},
title = {Unsupervised Learning of Depth and Ego-Motion From Monocular Video Using 3D Geometric Constraints},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Yeh_2018_CVPR,
author = {Yeh, Raymond A. and Do, Minh N. and Schwing, Alexander G.},
title = {Unsupervised Textual Grounding: Linking Words to Image Concepts},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}


@InProceedings{Li_2018_CVPR,
author = {Li, Siyang and Seybold, Bryan and Vorobyov, Alexey and Fathi, Alireza and Huang, Qin and Jay Kuo, C.-C.},
title = {Instance Embedding Transfer to Unsupervised Video Object Segmentation},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Lv_2018_CVPR,
author = {Lv, Jianming and Chen, Weihang and Li, Qing and Yang, Can},
title = {Unsupervised Cross-Dataset Person Re-Identification by Transfer Learning of Spatial-Temporal Patterns},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Chen_2018_CVPR,
author = {Chen, Qingchao and Liu, Yang and Wang, Zhaowen and Wassell, Ian and Chetty, Kevin},
title = {Re-Weighted Adversarial Adaptation Network for Unsupervised Domain Adaptation},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}


@InProceedings{Sener_2018_CVPR,
author = {Sener, Fadime and Yao, Angela},
title = {Unsupervised Learning and Segmentation of Complex Activities From Video},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Villegas_2018_CVPR,
author = {Villegas, Ruben and Yang, Jimei and Ceylan, Duygu and Lee, Honglak},
title = {Neural Kinematic Networks for Unsupervised Motion Retargetting},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Zhang_deep_2018_CVPR,
author = {Zhang, Jing and Zhang, Tong and Dai, Yuchao and Harandi, Mehrtash and Hartley, Richard},
title = {Deep Unsupervised Saliency Detection: A Multiple Noisy Labeling Perspective},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Pinheiro_2018_CVPR,
author = {Pinheiro, Pedro O.},
title = {Unsupervised Domain Adaptation With Similarity Learning},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Genova_2018_CVPR,
author = {Genova, Kyle and Cole, Forrester and Maschinot, Aaron and Sarna, Aaron and Vlasic, Daniel and Freeman, William T.},
title = {Unsupervised Training for 3D Morphable Model Regression},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Balakrishnan_2018_CVPR,
author = {Balakrishnan, Guha and Zhao, Amy and Sabuncu, Mert R. and Guttag, John and Dalca, Adrian V.},
title = {An Unsupervised Learning Model for Deformable Medical Image Registration},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Pumarola_2018_CVPR,
author = {Pumarola, Albert and Agudo, Antonio and Sanfeliu, Alberto and Moreno-Noguer, Francesc},
title = {Unsupervised Person Image Synthesis in Arbitrary Poses},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@inproceedings{kamnitsas_unsupervised_2017,
author="Kamnitsas, Konstantinos
and Baumgartner, Christian
and Ledig, Christian
and Newcombe, Virginia
and Simpson, Joanna
and Kane, Andrew
and Menon, David
and Nori, Aditya
and Criminisi, Antonio
and Rueckert, Daniel
and Glocker, Ben",
editor="Niethammer, Marc
and Styner, Martin
and Aylward, Stephen
and Zhu, Hongtu
and Oguz, Ipek
and Yap, Pew-Thian
and Shen, Dinggang",
title="Unsupervised Domain Adaptation in Brain Lesion Segmentation with Adversarial Networks",
booktitle="Information Processing in Medical Imaging",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="597--609",
abstract="Significant advances have been made towards building accurate automatic segmentation systems for a variety of biomedical applications using machine learning. However, the performance of these systems often degrades when they are applied on new data that differ from the training data, for example, due to variations in imaging protocols. Manually annotating new data for each test domain is not a feasible solution. In this work we investigate unsupervised domain adaptation using adversarial neural networks to train a segmentation method which is more robust to differences in the input data, and which does not require any annotations on the test domain. Specifically, we derive domain-invariant features by learning to counter an adversarial network, which attempts to classify the domain of the input data by observing the activations of the segmentation network. Furthermore, we propose a multi-connected domain discriminator for improved adversarial training. Our system is evaluated using two MR databases of subjects with traumatic brain injuries, acquired using different scanners and imaging protocols. Using our unsupervised approach, we obtain segmentation accuracies which are close to the upper bound of supervised domain adaptation.",
isbn="978-3-319-59050-9"
}



@inproceedings{boulch_unstructured_2017,
	booktitle = {Eurographics Workshop on 3D Object Retrieval},
editor = {Ioannis Pratikakis and Florent Dupont and Maks Ovsjanikov},
title = {{Unstructured Point Cloud Semantic Labeling Using Deep Segmentation Networks}},
author = {Boulch, Alexandre and Saux, Bertrand Le and Audebert, Nicolas},
year = {2017},
publisher = {The Eurographics Association},
ISSN = {1997-0471},
ISBN = {978-3-03868-030-7},
DOI = {10.2312/3dor.20171047}
}

@article{bengio_representation_2012,
 author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
 title = {Representation Learning: A Review and New Perspectives},
 journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
 issue_date = {August 2013},
 volume = {35},
 number = {8},
 month = aug,
 year = {2013},
 issn = {0162-8828},
 pages = {1798--1828},
 numpages = {31},
 url = {http://dx.doi.org/10.1109/TPAMI.2013.50},
 doi = {10.1109/TPAMI.2013.50},
 acmid = {2498889},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {Learning systems,Machine learning,Abstracts,Feature extraction,Manifolds,Neural networks,Speech recognition,neural nets,Deep learning,representation learning,feature learning,unsupervised learning,Boltzmann machine,autoencoder},
} 

@inproceedings{ronneberger_u-net:_2015-1,
	title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	isbn = {978-3-319-24574-4},
	series = {Lecture Notes in Computer Science},
	shorttitle = {U-Net},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the {ISBI} challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and {DIC}) we won the {ISBI} cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent {GPU}. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	pages = {234--241},
	booktitle = {Medical Image Computing and Computer-Assisted Intervention – {MICCAI} 2015},
	publisher = {Springer International Publishing},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	editor = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
	date = {2015},
	langid = {english},
	keywords = {Convolutional Layer, Data Augmentation, Deep Network, Ground Truth Segmentation, Training Image}
}

@article{brosch_deep_2016,
author={T. Brosch and L. Y. W. Tang and Y. Yoo and D. K. B. Li and A. Traboulsee and R. Tam}, 
journal={IEEE Transactions on Medical Imaging}, 
title={Deep 3D Convolutional Encoder Networks With Shortcuts for Multiscale Feature Integration Applied to Multiple Sclerosis Lesion Segmentation}, 
year={2016}, 
volume={35}, 
number={5}, 
pages={1229-1239}, 
keywords={biomedical MRI;feature extraction;image segmentation;medical image processing;neural nets;deep 3D convolutional encoder networks;multiscale feature integration;multiple sclerosis lesion segmentation;shortcut connections;magnetic resonance images;neural network;interconnected pathways;convolutional pathway;higher-level image features;deconvolutional pathway;voxel level;feature extraction;prediction pathways;automatic feature learning;segmentation task;low-level features;publicly available data sets;MICCAI 2008 challenges;ISBI 2015 challenges;top-ranked state-of-the-art methods;MS lesion segmentation methods;EMS;LST-LPA;LST-LGA;Lesion-TOADS;SLS;MS clinical trial;Image segmentation;Lesions;Convolution;Feature extraction;Imaging;Neural networks;Training;Convolutional neural networks;deep learning;machine learning;magnetic resonance imaging (MRI);multiple sclerosis lesions;segmentation;Algorithms;Brain;Humans;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Machine Learning;Magnetic Resonance Imaging;Multiple Sclerosis;Neural Networks (Computer)}, 
doi={10.1109/TMI.2016.2528821}, 
ISSN={0278-0062}, 
month={May},}

@inproceedings{brosch_deep_2015,
	author="Brosch, Tom
and Yoo, Youngjin
and Tang, Lisa Y. W.
and Li, David K. B.
and Traboulsee, Anthony
and Tam, Roger",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="Deep Convolutional Encoder Networks for Multiple Sclerosis Lesion Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="3--11",
abstract="We propose a novel segmentation approach based on deep convolutional encoder networks and apply it to the segmentation of multiple sclerosis (MS) lesions in magnetic resonance images. Our model is a neural network that has both convolutional and deconvolutional layers, and combines feature extraction and segmentation prediction in a single model. The joint training of the feature extraction and prediction layers allows the model to automatically learn features that are optimized for accuracy for any given combination of image types. In contrast to existing automatic feature learning approaches, which are typically patch-based, our model learns features from entire images, which eliminates patch selection and redundant calculations at the overlap of neighboring patches and thereby speeds up the training. Our network also uses a novel objective function that works well for segmenting underrepresented classes, such as MS lesions. We have evaluated our method on the publicly available labeled cases from the MS lesion segmentation challenge 2008 data set, showing that our method performs comparably to the state-of-theart. In addition, we have evaluated our method on the images of 500 subjects from an MS clinical trial and varied the number of training samples from 5 to 250 to show that the segmentation performance can be greatly improved by having a representative data set.",
isbn="978-3-319-24574-4"
}



@article{avendi_combined_2016,
title = "A combined deep-learning and deformable-model approach to fully automatic segmentation of the left ventricle in cardiac MRI",
journal = "Medical Image Analysis",
volume = "30",
pages = "108 - 119",
year = "2016",
issn = "1361-8415",
doi = "https://doi.org/10.1016/j.media.2016.01.005",
url = "http://www.sciencedirect.com/science/article/pii/S1361841516000128",
author = "M.R. Avendi and Arash Kheradvar and Hamid Jafarkhani",
keywords = "Caridac MRI, LV segmentation, Deep learning, Machine learning, Deformable models"
}

@article{romero_unsupervised_2016,
author={A. Romero and C. Gatta and G. Camps-Valls}, 
journal={IEEE Transactions on Geoscience and Remote Sensing}, 
title={Unsupervised Deep Feature Extraction for Remote Sensing Image Classification}, 
year={2016}, 
volume={54}, 
number={3}, 
pages={1349-1362}, 
keywords={feature extraction;geophysical image processing;hyperspectral imaging;image classification;land cover;land use;principal component analysis;remote sensing;unsupervised learning;unsupervised deep feature extraction;remote sensing image classification;single-layer network;deep convolutional network;remote sensing data analysis;multiimagery;hyperspectral imagery;supervised convolutional network;unsupervised learning;sparse feature;sparse representation;aerial scene classification;land use classification;land cover classification;multiimages;hyperspectral images;kernel principal component analysis;Feature extraction;Remote sensing;Training;Computer architecture;Unsupervised learning;Sociology;Statistics;Aerial image classification;classification;deep convolutional networks;deep learning;feature extraction;hyperspectral (HS) image;multispectral (MS) images;segmentation;sparse features learning;very high resolution (VHR);Aerial image classification;classification;deep convolutional networks;deep learning;feature extraction;hyperspectral (HS) image;multispectral (MS) images;segmentation;sparse features learning;very high resolution (VHR)}, 
doi={10.1109/TGRS.2015.2478379}, 
ISSN={0196-2892}, 
month={March},}

@article{simonyan_deep_2013,
	title = {Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps},
	url = {http://arxiv.org/abs/1312.6034},
	shorttitle = {Deep Inside Convolutional Networks},
	abstract = {This paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks ({ConvNets}). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score [Erhan et al., 2009], thus visualising the notion of the class, captured by a {ConvNet}. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification {ConvNets}. Finally, we establish the connection between the gradient-based {ConvNet} visualisation methods and deconvolutional networks [Zeiler et al., 2013].},
	journaltitle = {{arXiv}:1312.6034 [cs]},
	author = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
	urldate = {2018-09-15},
	date = {2013-12-20},
	eprinttype = {arxiv},
	eprint = {1312.6034},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1312.6034 PDF:/Users/Marc/Zotero/storage/NR4425FF/Simonyan et al. - 2013 - Deep Inside Convolutional Networks Visualising Im.pdf:application/pdf;arXiv.org Snapshot:/Users/Marc/Zotero/storage/MDBZ6WE2/1312.html:text/html}
}

@article{cimpoi_deep_2015,
author = {Cimpoi, Mircea and Maji, Subhransu and Kokkinos, Iasonas and Vedaldi, Andrea},
 title = {Deep Filter Banks for Texture Recognition, Description, and Segmentation},
 journal = {Int. J. Comput. Vision},
 issue_date = {May       2016},
 volume = {118},
 number = {1},
 month = may,
 year = {2016},
 issn = {0920-5691},
 pages = {65--94},
 numpages = {30},
 url = {http://dx.doi.org/10.1007/s11263-015-0872-3},
 doi = {10.1007/s11263-015-0872-3},
 acmid = {2935085},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {Convolutional neural networks, Datasets and benchmarks, Filter banks, Fisher vectors, Texture and material recognition, Visual attributes},
}

@article{shu_unsupervised_2016,
title = "Unsupervised 3D shape segmentation and co-segmentation via deep learning",
journal = "Computer Aided Geometric Design",
volume = "43",
pages = "39 - 52",
year = "2016",
note = "Geometric Modeling and Processing 2016",
issn = "0167-8396",
doi = "https://doi.org/10.1016/j.cagd.2016.02.015",
url = "http://www.sciencedirect.com/science/article/pii/S0167839616300164",
author = "Zhenyu Shu and Chengwu Qi and Shiqing Xin and Chao Hu and Li Wang and Yu Zhang and Ligang Liu",
keywords = "3D shapes, Segmentation, Co-segmentation, Deep learning, High-level features"
}

@article{liskowski_segmenting_2016,
author={P. Liskowski and K. Krawiec}, 
journal={IEEE Transactions on Medical Imaging}, 
title={Segmenting Retinal Blood Vessels With Deep Neural Networks}, 
year={2016}, 
volume={35}, 
number={11}, 
pages={2369-2380}, 
keywords={blood vessels;eye;image classification;image segmentation;medical image processing;neural nets;sensitivity analysis;unsupervised learning;retinal blood vessel segmentation;deep neural networks;vascular network;human eye;diagnostic factor;ophthalmology;fundus imaging;nontrivial task;microaneurysms;hemorrhages;supervised segmentation;global contrast normalization;zero-phase whitening;geometric transformations;gamma corrections;structured prediction;DRIVE databases;STARE databases;CHASE databases;ROC curve;image classification;central vessel reflex;Image segmentation;Biomedical imaging;Databases;Blood vessels;Neural networks;Pathology;Convolution;Classification;deep learning;feature learning;fundus;neural networks;retina;retinopathy;structured prediction;vessel segmentation;Databases, Factual;Humans;Image Interpretation, Computer-Assisted;Neural Networks (Computer);Retinal Vessels;Supervised Machine Learning}, 
doi={10.1109/TMI.2016.2546227}, 
ISSN={0278-0062}, 
month={Nov},}

@article{badrinarayanan_segnet:_2015,
author={V. Badrinarayanan and A. Kendall and R. Cipolla}, 
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
title={SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation}, 
year={2017}, 
volume={39}, 
number={12}, 
pages={2481-2495}, 
keywords={feature extraction;gradient methods;image classification;image colour analysis;image representation;image resolution;image segmentation;inference mechanisms;learning (artificial intelligence);self-organising feature maps;topology;convolutional layers;SegNet;decoder network;low resolution encoder feature maps;DeconvNet architectures;DeepLab-LargeFOV;FCN;stochastic gradient descent;SUN RGB-D indoor scene segmentation;competitive inference time;Caffe implementation;SUN RGB-D indoor scene segmentation tasks;dense feature maps;nonlinear upsampling;max-pooling step;lower resolution input feature map;VGG16 network;pixel-wise classification layer;encoder network;core trainable segmentation engine;pixel-wise segmentation;practical deep fully convolutional neural network architecture;image segmentation;deep convolutional encoder-decoder architecture;Decoding;Neural networks;Training;Computer architecture;Image segmentation;Semantics;Convolutional codes;Deep convolutional neural networks;semantic pixel-wise segmentation;indoor scenes;road scenes;encoder;decoder;pooling;upsampling}, 
doi={10.1109/TPAMI.2016.2644615}, 
ISSN={0162-8828}, 
month={Dec},}

@online{noauthor_survey_nodate,
	title = {A survey on deep learning in medical image analysis},
	url = {https://reader.elsevier.com/reader/sd/pii/S1361841517301135?token=567706A041E790228842BB923B19C4793EBE4C9FCCDE7C31D1E34F21FC36974864C1D1FCAC24072182E6125927CFE99C},
	urldate = {2018-09-19},
	langid = {english},
	doi = {10.1016/j.media.2017.07.005}
}

@online{noauthor_learning_nodate,
	title = {Learning graph affinities for spectral graph-based salient object detection},
	url = {https://reader.elsevier.com/reader/sd/pii/S0031320316303570?token=356D99C4E78E45761CB39F95626AE60479ED505187A75FC4C58251BC31CEDB1E2D973B5E72D8B7A032188324A5A7CCEA},
	urldate = {2018-09-19},
	langid = {english},
	doi = {10.1016/j.patcog.2016.11.005},
	file = {Snapshot:/Users/Marc/Zotero/storage/QDSK588N/S0031320316303570.html:text/html}
}

@online{noauthor_category-specific_nodate,
	title = {Category-specific object segmentation via unsupervised discriminant shape},
	url = {https://reader.elsevier.com/reader/sd/pii/S0031320316303594?token=1EDF7C5CF276FBE7003F5E091369865D9BA8A1084FC1122E576D383E576A106181C779E296A234DFA472713389F9DC57},
	urldate = {2018-09-19},
	langid = {english},
	doi = {10.1016/j.patcog.2016.11.009},
	file = {Snapshot:/Users/Marc/Zotero/storage/HU8F3WK2/S0031320316303594.html:text/html}
}

@article{garcia_article,
title = "A survey on deep learning techniques for image and video semantic segmentation",
journal = "Applied Soft Computing",
volume = "70",
pages = "41 - 65",
year = "2018",
issn = "1568-4946",
doi = "https://doi.org/10.1016/j.asoc.2018.05.018",
url = "http://www.sciencedirect.com/science/article/pii/S1568494618302813",
author = "Alberto Garcia-Garcia and Sergio Orts-Escolano and Sergiu Oprea and Victor Villena-Martinez and Pablo Martinez-Gonzalez and Jose Garcia-Rodriguez",
keywords = "Semantic segmentation, Deep learning, Scene labeling"
}

@article{zhao_deep_2018,
title = "A deep learning model integrating FCNNs and CRFs for brain tumor segmentation",
journal = "Medical Image Analysis",
volume = "43",
pages = "98 - 111",
year = "2018",
issn = "1361-8415",
doi = "https://doi.org/10.1016/j.media.2017.10.002",
url = "http://www.sciencedirect.com/science/article/pii/S136184151730141X",
author = "Xiaomei Zhao and Yihong Wu and Guidong Song and Zhenye Li and Yazhuo Zhang and Yong Fan",
keywords = "Brain tumor segmentation, Fully convolutional neural networks, Conditional random fields, Deep learning"
}

@article{kamnitsas_efficient_2017,
title = "Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation",
journal = "Medical Image Analysis",
volume = "36",
pages = "61 - 78",
year = "2017",
issn = "1361-8415",
doi = "https://doi.org/10.1016/j.media.2016.10.004",
url = "http://www.sciencedirect.com/science/article/pii/S1361841516301839",
author = "Konstantinos Kamnitsas and Christian Ledig and Virginia F.J. Newcombe and Joanna P. Simpson and Andrew D. Kane and David K. Menon and Daniel Rueckert and Ben Glocker",
keywords = "3D convolutional neural network, Fully connected CRF, Segmentation, Brain lesions, Deep learning"
}

@article{affonso_deep_2017,
title = "Deep learning for biological image classification",
journal = "Expert Systems with Applications",
volume = "85",
pages = "114 - 122",
year = "2017",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2017.05.039",
url = "http://www.sciencedirect.com/science/article/pii/S0957417417303627",
author = "Carlos Affonso and André Luis Debiaso Rossi and Fábio Henrique Antunes Vieira and André Carlos Ponce de Leon Ferreira de Carvalho",
keywords = "Wood classification, Deep learning, Image classification, Machine learning"
}

@article{gibson_niftynet:_2018,
	title = "NiftyNet: a deep-learning platform for medical imaging",
journal = "Computer Methods and Programs in Biomedicine",
volume = "158",
pages = "113 - 122",
year = "2018",
issn = "0169-2607",
doi = "https://doi.org/10.1016/j.cmpb.2018.01.025",
url = "http://www.sciencedirect.com/science/article/pii/S0169260717311823",
author = "Eli Gibson and Wenqi Li and Carole Sudre and Lucas Fidon and Dzhoshkun I. Shakir and Guotai Wang and Zach Eaton-Rosen and Robert Gray and Tom Doel and Yipeng Hu and Tom Whyntie and Parashkev Nachev and Marc Modat and Dean C. Barratt and Sébastien Ourselin and M. Jorge Cardoso and Tom Vercauteren",
keywords = "Medical image analysis, Deep learning, Convolutional neural network, Segmentation, Image regression, Generative adversarial network"
}


@article{xu2018youtube,
title={YouTube-VOS: A Large-Scale Video Object Segmentation Benchmark},
author={Xu, Ning and Yang, Linjie and Fan, Yuchen and Yue, Dingcheng and Liang, Yuchen and Yang, Jianchao and Huang, Thomas},
journal={arXiv preprint arXiv:1809.03327},
year={2018}
}

@InProceedings{Long_2015_CVPR,
author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
title = {Fully Convolutional Networks for Semantic Segmentation},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2015}
}

@inproceedings{szegedy_deeper,
title	= {Going Deeper with Convolutions},
author	= {Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich},
year	= {2015},
URL	= {http://arxiv.org/abs/1409.4842},
booktitle	= {Computer Vision and Pattern Recognition (CVPR)}
}

@article{simonyan_very_deep,
  author    = {Karen Simonyan and
               Andrew Zisserman},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1409.1556},
  year      = {2014},
  url       = {http://arxiv.org/abs/1409.1556},
  archivePrefix = {arXiv},
  eprint    = {1409.1556},
  timestamp = {Mon, 13 Aug 2018 16:46:51 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SimonyanZ14a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{he_deep_residual, 
author={K. He and X. Zhang and S. Ren and J. Sun}, 
booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
title={Deep Residual Learning for Image Recognition}, 
year={2016}, 
volume={}, 
number={}, 
pages={770-778}, 
keywords={image classification;learning (artificial intelligence);neural nets;object detection;COCO segmentation;ImageNet localization;ILSVRC & COCO 2015 competitions;deep residual nets;COCO object detection dataset;visual recognition tasks;CIFAR-10;ILSVRC 2015 classification task;ImageNet test set;VGG nets;residual nets;ImageNet dataset;residual function learning;deeper neural network training;image recognition;deep residual learning;Training;Degradation;Complexity theory;Image recognition;Neural networks;Visualization;Image segmentation}, 
doi={10.1109/CVPR.2016.90}, 
ISSN={1063-6919}, 
month={June},}

@InProceedings{Visin_2016_CVPR_Workshops,
author = {Visin, Francesco and Ciccone, Marco and Romero, Adriana and Kastner, Kyle and Cho, Kyunghyun and Bengio, Yoshua and Matteucci, Matteo and Courville, Aaron},
title = {ReSeg: A Recurrent Neural Network-Based Model for Semantic Segmentation},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2016}
}

@article{NgoLC17_combining,
  author    = {Tuan Anh Ngo and
               Zhi Lu and
               Gustavo Carneiro},
  title     = {Combining deep learning and level set for the automated segmentation
               of the left ventricle of the heart from cardiac cine magnetic resonance},
  journal   = {Medical Image Analysis},
  volume    = {35},
  pages     = {159--171},
  year      = {2017},
  url       = {https://doi.org/10.1016/j.media.2016.05.009},
  doi       = {10.1016/j.media.2016.05.009},
  timestamp = {Wed, 14 Jun 2017 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/mia/NgoLC17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{milletari_vnet,
  author    = {Fausto Milletari and
               Nassir Navab and
               Seyed{-}Ahmad Ahmadi},
  title     = {V-Net: Fully Convolutional Neural Networks for Volumetric Medical
               Image Segmentation},
  booktitle = {Fourth International Conference on 3D Vision, 3DV 2016, Stanford,
               CA, USA, October 25-28, 2016},
  pages     = {565--571},
  year      = {2016},
  url       = {https://doi.org/10.1109/3DV.2016.79},
  doi       = {10.1109/3DV.2016.79},
  timestamp = {Tue, 23 May 2017 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/3dim/MilletariNA16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{aytekin_learning_graph,
title = "Learning graph affinities for spectral graph-based salient object detection",
abstract = "In this paper, we propose a novel method for learning graph affinities for salient object detection. First, we assume that a graph representation of an image is given with a predetermined connectivity rule and representative features for each of its nodes. Then, we learn to predict affinities related to this graph, that ensures a decent salient object detection performance, when used with a spectral graph based foreground detection method. To accomplish this task, we modify convolutional kernel networks (CKNs) for graph affinity calculation, which were originally proposed to predict similarities between images. Subsequently, we employ a spectral graph based salient object detection method – Extended Quantum Cuts (EQCut) – using these graph affinities. We show that the salient object detection error of such a system is differentiable with respect to the parameters of the CKN. Therefore, the proposed system can be trained end-to-end by applying error backpropagation and CKN parameters can be learned for salient object detection task. The comparative evaluations over a large set of benchmark datasets indicate that the proposed method has an insignificant computational burden on, but significantly outperforms the baseline EQCut – which uses color affinities – and achieves a comparable performance level with the state-of-the-art in some performance measures.",
author = "Caglar Aytekin and Alexandros Iosifidis and Serkan Kiranyaz and Moncef Gabbouj",
note = "EXT={"}Kiranyaz, Serkan{"}",
year = "2016",
month = "11",
day = "12",
doi = "10.1016/j.patcog.2016.11.005",
language = "English",
volume = "64",
pages = "159--167",
journal = "Pattern Recognition",
issn = "0031-3203",
publisher = "ELSEVIER SCI LTD",
}

@InProceedings{Pathak_2015_ICCV,
author = {Pathak, Deepak and Krahenbuhl, Philipp and Darrell, Trevor},
title = {Constrained Convolutional Neural Networks for Weakly Supervised Segmentation},
booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
month = {December},
year = {2015}
}

@article{zhang2014representative,
  title={Representative discovery of structure cues for weakly-supervised image segmentation},
  author={ZHANG, Luming and GAO, Yue and XIA, Yingjie and LU, Ke and SHEN, Jialie and JI, Rongrong},
  journal={IEEE Transactions on Multimedia},
  volume={16},
  number={2},
  pages={470},
  year={2014},
  publisher={IEEE}
}

article{zhang2014probabilistic,
  title={A probabilistic associative model for segmenting weakly supervised images},
  author={Zhang, Luming and Yang, Yi and Gao, Yue and Yu, Yi and Wang, Changbo and Li, Xuelong},
  journal={IEEE Transactions on Image Processing},
  volume={23},
  number={9},
  pages={4150--4159},
  year={2014},
  publisher={IEEE}
}

@ARTICLE{gibson_automatic, 
author={E. Gibson and F. Giganti and Y. Hu and E. Bonmati and S. Bandula and K. Gurusamy and B. Davidson and S. P. Pereira and M. J. Clarkson and D. C. Barratt}, 
journal={IEEE Transactions on Medical Imaging}, 
title={Automatic Multi-Organ Segmentation on Abdominal CT With Dense V-Networks}, 
year={2018}, 
volume={37}, 
number={8}, 
pages={1822-1834}, 
keywords={biological organs;biomedical MRI;computerised tomography;endoscopes;image fusion;image registration;image segmentation;kidney;learning (artificial intelligence);liver;medical image processing;statistical analysis;image-guided navigation;multiorgan abdominal CT segmentation;registration-free method;multicentre data;existing deep learning;endoscopic pancreatic procedures;registration-free deep-learning-based segmentation algorithm;abdominal organs;alternative methods;abdominal images;inter-subject image registrations;statistical models;segmentation methods;computed tomography images;abdominal anatomy;automatic segmentation;automatic multiorgan segmentation;Image segmentation;Computed tomography;Liver;Kidney;Three-dimensional displays;Pancreas;Abdominal CT;segmentation;deep learning;pancreas;gastrointestinal tract;stomach;duodenum;esophagus;liver;spleen;kidney;gallbladder}, 
doi={10.1109/TMI.2018.2806309}, 
ISSN={0278-0062}, 
month={Aug},}

@article{zhang2014probabilistic,
author={L. Zhang and Y. Yang and Y. Gao and Y. Yu and C. Wang and X. Li}, 
journal={IEEE Transactions on Image Processing}, 
title={A Probabilistic Associative Model for Segmenting Weakly Supervised Images}, 
year={2014}, 
volume={23}, 
number={9}, 
pages={4150-4159}, 
keywords={belief networks;graph theory;image segmentation;learning (artificial intelligence);pattern recognition;probability;training;image categorization;probabilistic associative model;weakly supervised image segmentation;image processing;pattern recognition;semantic labels;semantic associations;superpixel sets;manifold graphlet embedding algorithm;feature vectors;hierarchical Bayesian network;segmentation based photo cropping;Image segmentation;Semantics;Context;Manifolds;Vectors;Optimization;Computational modeling;Probabilistic model;weakly-supervised;segmentation;associations}, 
doi={10.1109/TIP.2014.2344433}, 
ISSN={1057-7149}, 
month={Sept},}

@article{hoo-chang,
 author = {Shin, Hoo-Chang and Roth, Holger R. and Gao, Mingchen and Lu, Le and Xu, Ziyue and Nogues, Isabella and Yao, Jianhua and Mollura, Daniel and Summers, Ronald M.},
 doi = {10.1109/tmi.2016.2528162},
 journal = {IEEE Transactions on Medical Imaging },
 keywords = {Artificial Intelligence and Image Processing},
 note = {Exported from https://app.dimensions.ai on 2018/10/13},
 number = {5},
 pages = {1285-1298},
 title = {Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning},
 url = {https://app.dimensions.ai/details/publication/pub.1061696701 and http://arxiv.org/pdf/1602.03409},
 volume = {35},
 year = {2016}
}

@article{simonyan_VGG,
  author    = {Karen Simonyan and
               Andrew Zisserman},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1409.1556},
  year      = {2014},
  url       = {http://arxiv.org/abs/1409.1556},
  archivePrefix = {arXiv},
  eprint    = {1409.1556},
  timestamp = {Mon, 13 Aug 2018 16:46:51 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SimonyanZ14a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{mcinerney1996deformable,
  title={Deformable models in medical image analysis: a survey},
  author={McInerney, Tim and Terzopoulos, Demetri},
  journal={Medical image analysis},
  volume={1},
  number={2},
  pages={91--108},
  year={1996},
  publisher={Elsevier}
}

@article{yangdeformable20043d,
  title={3D image segmentation of deformable objects with joint shape-intensity prior models using level sets},
  author={Yang, Jing and Duncan, James S},
  journal={Medical image analysis},
  volume={8},
  number={3},
  pages={285--294},
  year={2004},
  publisher={Elsevier}
}